---
---

@article{wang2025systematic,
abbr={CSUR},
author = {Wang, Xian and Shen, Luyao and Lee, Lik-Hang},
title = {A Systematic Review of XR-Enabled Remote Human-Robot Interaction Systems},
year = {2025},
publisher = {Association for Computing Machinery},
issn = {0360-0300},
url = {https://doi.org/10.1145/3730574},
doi = {10.1145/3730574},
journal = {ACM Comput. Surv.},
selected={true},
preview={robot.png},
abstract={The rising interest in creating versatile robots to handle multiple tasks in various environments, with humans interacting through immersive interfaces. This survey provides a comprehensive review of extended reality (XR) applications in remote human-robot interaction (HRI). We developed a systematic search strategy based on the PRISMA methodology, focusing on peer-reviewed publications that demonstrate practical implementations of XR in remote robot control, real robot system deployment, and HRI applications, we analyzed research published between January 2013 and December 2023. From the initial 2,561 articles, 100 met our inclusion criteria were included. We categorized and summarized the domain in detail, delving into the methods used in these articles to achieve intuitive and effective remote HRI, highlighting user experience enhancement and interaction designs. This survey identifies research opportunities, particularly emphasizes that future researchers should explore the potential of XR, such as exploring multimodal enhancement techniques that seamlessly integrate visual, haptic, and auditory feedback for more intuitive teleoperation. Our analysis reveals that while XR shows promising potential in remote HRI, there are significant gaps, such as user-centered design. This survey provides a framework for understanding the current state of XR-based remote HRI, establishing a foundation for future research.}
}

@article{wang2025teamportal,
  abbr={TVCG},
  author={Wang, Xian and Shen, Luyao and Chen, Lei and Fan, Mingming and Lee, Lik-Hang},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={TeamPortal: Exploring Virtual Reality Collaboration Through Shared and Manipulating Parallel Views}, 
  year={2025},
  pages={1--11},
  doi={10.1109/TVCG.2025.3549569},
  selected={true},
  preview={TeamPortal.png},
  url={https://ieeexplore.ieee.org/document/10918848},
  video={https://youtu.be/_STN5eHf-cY},
  abstract={Virtual Reality (VR) offers a unique collaborative experience, with parallel views playing a pivotal role in Collaborative Virtual Environments by supporting the transfer and delivery of items. Sharing and manipulating partners' views provides users with a broader perspective that helps them identify the targets and partner actions. We proposed TeamPortal accordingly and conducted two user studies with 72 participants (36 pairs) to investigate the potential benefits of interactive, shared perspectives in VR collaboration. Our first study compared ShaView and TeamPortal against a baseline in a collaborative task that encompassed a series of searching and manipulation tasks. The results show that TeamPortal significantly reduced movement and increased collaborative efficiency and social presence in complex tasks. Following the results, the second study evaluated three variants: TeamPortal+, SnapTeamPortal+, and DropTeamPortal+. The results show that both SnapTeamPortal+ and DropTeamPortal+ improved task efficiency and willingness to further adopt these technologies, though SnapTeamPortal+ reduced co-presence. Based on the findings, we proposed three design implications to inform the development of future VR collaboration systems.}
}

@article{zheng2025lmlpa,
    author = {Zheng, Jingyao and Wang, Xian and Hosio, Simo and Xu, Xiaoxian and Lee, Lik-Hang},
    title = {LMLPA: Language Model Linguistic Personality Assessment},
    journal = {Computational Linguistics},
    pages = {1--42},
    year = {2025},
    month = {03},
    doi = {10.1162/coli_a_00550},
    preview={LMLPA.png},
    url = {https://doi.org/10.1162/coli\_a\_00550}
}

@article{wang2024dark,
  abbr={IJHCI},
  title={The dark side of augmented reality: Exploring manipulative designs in AR},
  author={Wang, Xian and Lee, Lik-Hang and Bermejo Fernandez, Carlos and Hui, Pan},
  journal={International Journal of Human--Computer Interaction},
  volume={40},
  number={13},
  pages={3449--3464},
  year={2024},
  publisher={Taylor \& Francis},
  selected={true},
  preview={darkpattern.png},
  doi={10.1080/10447318.2023.2188799},
  altmetric={true},
  dimensions={true},
  url={https://www.tandfonline.com/doi/abs/10.1080/10447318.2023.2188799},
  abstract={Augmented Reality (AR) applications are becoming more mainstream, with successful examples in the mobile environment like Pokemon GO. Current malicious techniques can exploit these environments’ immersive and mixed nature (physical-virtual) to trick users into providing more personal information, i.e., dark patterns. Dark patterns are deceiving techniques (e.g., interface tricks) designed to influence individuals’ behavioural decisions. However, there are few studies regarding dark patterns’ potential issues in AR environments. In this work, using scenario construction to build our prototypes, we investigate the potential future approaches that dark patterns can have. We use VR mockups in our user study to analyze the effects of dark patterns in AR. Our study indicates that dark patterns are effective in immersive scenarios, and the use of novel techniques, such as “haptic grabbing” to draw participants’ attention, can influence their movements. Finally, we discuss the impact of such malicious techniques and what techniques can mitigate them.},
  video={https://youtu.be/WUCnzVYIiBU}
}

@inproceedings{wang2023designing,
  abbr={ACM MM},
  title={Designing Loving-Kindness Meditation in Virtual Reality for Long-Distance Romantic Relationships},
  author={Wang, Xian and Mo, Xiaoyu and Lee, Lik-Hang and Wei, Xiaoying and Jin, Xiaofu and Fan, Mingming and Hui, Pan},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={7608--7617},
  year={2023},
  selected={true},
  preview={meditation.jpg},
  doi={10.1145/3581783.3612438},
  url={https://dl.acm.org/doi/abs/10.1145/3581783.3612438},
  abstract={Loving-kindness meditation (LKM) is used in clinical psychology for couples' relationship therapy, but physical isolation can make the relationship more strained and inaccessible to LKM. Virtual reality (VR) can provide immersive LKM activities for long-distance couples. However, no suitable commercial VR applications for couples exist to engage in LKM activities of long-distance. This paper organized a series of workshops with couples to build a prototype of a couple-preferred LKM app. Through analysis of participants' design works and semi-structured interviews, we derived design considerations for such VR apps and created a prototype for couples to experience. We conducted a study with couples to understand their experiences of performing LKM using the VR prototype and a traditional video conferencing tool. Results show that LKM session utilizing both tools has a positive effect on the intimate relationship and the VR prototype is a more preferable tool for long-term use. We believe our experience can inform future researchers.},
  video={https://youtu.be/KnkReForfWM}
}

@inproceedings{wang2022vibroweight,
  abbr={HAPTICS},
  title={Vibroweight: Simulating weight and center of gravity changes of objects in virtual reality for enhanced realism},
  author={Wang, Xian and Monteiro, Diego and Lee, Lik-Hang and Hui, Pan and Liang, Hai-Ning},
  booktitle={2022 IEEE haptics symposium (HAPTICS)},
  pages={1--7},
  year={2022},
  organization={IEEE},
  selected={true},
  preview={vibroweight.png},
  doi={10.1109/HAPTICS52432.2022.9765609},
  dimensions={true},
  url={https://ieeexplore.ieee.org/abstract/document/9765609},
  video={https://youtu.be/ptMbLT-tLrY},
  abstract={Haptic feedback in virtual reality (VR) allows users to perceive the physical properties of virtual objects (e.g., their weight and motion patterns). However, the lack of haptic sensations deteriorates users' immersion and overall experience. In this work, we designed and implemented a low-cost hardware prototype with liquid metal, VibroWeight, which can work in complementarity with commercial VR handheld controllers. VibroWeight is characterized by bimodal feedback cues in VR, driven by adaptive absolute mass (weights) and gravity shift. To our knowledge, liquid metal is used in a VR haptic device for the first time. Our 29 participants show that VibroWeight delivers significantly better VR experiences in realism and comfort.},
  annotation={* Vibroweight is a device for weight and center of gravity simulation in VR. The previous research is our article in 2021: Design and development of a low-cost device for weight and center of gravity simulation in virtual reality, and the related work has been authorized by China patent (CN112083803B).}
}

@inproceedings{wang2022reducing,
  abbr={Chinese CHI},
  title={Reducing stress and anxiety in the metaverse: A systematic review of meditation, mindfulness and virtual reality},
  author={Wang, Xian and Mo, Xiaoyu and Fan, Mingming and Lee, Lik-Hang and Shi, Bertram and Hui, Pan},
  booktitle={Proceedings of the Tenth International Symposium of Chinese CHI},
  pages={170--180},
  year={2022},
  selected={true},
  preview={reducing_stress.png},
  doi={10.1145/3565698.3565781},
  dimensions={true},
  url={https://dl.acm.org/doi/abs/10.1145/3565698.3565781}
}

@inproceedings{monteiro2018evaluating,
  title={Evaluating the effects of a cartoon-like character with emotions on users' behaviour within virtual reality environments},
  author={Monteiro, Diego and Liang, Hai-Ning and Wang, Jialin and Wang, Luhan and Wang, Xian and Yue, Yong},
  booktitle={2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)},
  pages={229--236},
  year={2018},
  organization={IEEE Computer Society}
}

@inproceedings{monteiro2021design,
  title={Design and development of a low-cost device for weight and center of gravity simulation in virtual reality},
  author={Monteiro, Diego and Liang, Hai-Ning and Wang, Xian and Xu, Wenge and Tu, Huawei},
  booktitle={Proceedings of the 2021 International Conference on Multimodal Interaction},
  pages={453--460},
  year={2021}
}

@inproceedings{wei2023bridging,
  abbr={CHI},
  title={Bridging the generational gap: exploring how virtual reality supports remote communication between grandparents and grandchildren},
  author={Wei, Xiaoying and Gu, Yizheng and Kuang, Emily and Wang, Xian and Cao, Beiyan and Jin, Xiaofu and Fan, Mingming},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--15},
  preview={Xiaoying.png},
  year={2023}
}

@inproceedings{monteiro2020evaluating,
  title={Evaluating the need and effect of an audience in a virtual reality presentation training tool},
  author={Monteiro, Diego and Liang, Hai-Ning and Li, Hongji and Fu, Yu and Wang, Xian},
  booktitle={Computer Animation and Social Agents: 33rd International Conference on Computer Animation and Social Agents, CASA 2020, Bournemouth, UK, October 13-15, 2020, Proceedings 33},
  pages={62--70},
  year={2020},
  organization={Springer}
}

@inproceedings{jin2024exploring,
  abbr={CHI},
  title={Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults to Explore and Learn Smartphone Applications},
  author={Jin, Xiaofu and Tong, Wai and Wei, Xiaoying and Wang, Xian and Kuang, Emily and Mo, Xiaoyu and Qu, Huamin and Fan, Mingming},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--18},
  preview={Xiaofu.png},
  year={2024}
}

@article{shen2024emojichat,
  abbr={IJHCI},
  title={EmojiChat: Toward Designing Emoji-Driven Social Interaction in VR Museums},
  author={Shen, Luyao and Wang, Xian and Li, Sijia and Lee, Lik-Hang and Fan, Mingming and Hui, Pan},
  journal={International Journal of Human--Computer Interaction},
  pages={1--17},
  year={2024},
  preview={EmojiChat.png},
  publisher={Taylor \& Francis}
}

@inproceedings{shan2023immersive,
  title={An immersive simulator for improving chemistry learning efficiency},
  author={Shan, Jin and Wang, Yuyang and Lee, Lik-Hang and Wang, Xian and Chen, Zeming and Dong, Boya and Luo, Xinyi and Hui, Pan},
  booktitle={2023 IEEE conference on virtual reality and 3d user interfaces abstracts and workshops (VRW)},
  pages={841--842},
  year={2023},
  organization={IEEE}
}

@inproceedings{yang2024prompt,
  title={From Prompt to Metaverse: User Perceptions of Personalized Spaces Crafted by Generative AI},
  author={Yang, Simin and Tsui, Yuk Hang and Wang, Xian and Alhilal, Ahmad and Hadi Mogavi, Reza and Wang, Xuetong and Hui, Pan},
  booktitle={Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
  pages={497--504},
  year={2024}
}

@inproceedings{monteiro2021spatial,
  title={Spatial Knowledge Acquisition in Virtual and Physical Reality: A Comparative Evaluation},
  author={Monteiro, Diego and Wang, Xian and Liang, Hai-Ning and Cai, Yiyu},
  booktitle={2021 IEEE 7th International Conference on Virtual Reality (ICVR)},
  pages={308--313},
  year={2021},
  organization={IEEE}
}
